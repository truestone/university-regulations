# frozen_string_literal: true

# íŒŒì„œ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí‚¹ ë„êµ¬
class ParserBenchmark
  attr_reader :metrics

  def initialize
    @start_time = nil
    @end_time = nil
    @start_memory = nil
    @peak_memory = nil
    @processed_lines = 0
    @errors = []
    @checkpoints = []
  end

  # ë²¤ì¹˜ë§ˆí¬ ì‹œì‘
  def start
    @start_time = Time.now
    @start_memory = current_memory_usage
    @processed_lines = 0
    @errors = []
    @checkpoints = []
    
    log_checkpoint("Benchmark started")
  end

  # ë²¤ì¹˜ë§ˆí¬ ì¢…ë£Œ
  def finish
    @end_time = Time.now
    @peak_memory = current_memory_usage
    
    log_checkpoint("Benchmark finished")
    calculate_metrics
  end

  # ë¼ì¸ ì²˜ë¦¬ ê¸°ë¡
  def record_line_processed
    @processed_lines += 1
    
    # 1000ë¼ì¸ë§ˆë‹¤ ì²´í¬í¬ì¸íŠ¸ ê¸°ë¡
    if @processed_lines % 1000 == 0
      log_checkpoint("Processed #{@processed_lines} lines")
    end
  end

  # ì—ëŸ¬ ê¸°ë¡
  def record_error(error)
    @errors << {
      error: error,
      timestamp: Time.now,
      line_number: @processed_lines,
      memory_usage: current_memory_usage
    }
  end

  # ì²´í¬í¬ì¸íŠ¸ ê¸°ë¡
  def log_checkpoint(message)
    @checkpoints << {
      message: message,
      timestamp: Time.now,
      memory_usage: current_memory_usage,
      processed_lines: @processed_lines
    }
  end

  # ë©”íŠ¸ë¦­ ê³„ì‚°
  def calculate_metrics
    duration = @end_time - @start_time
    memory_used = @peak_memory - @start_memory
    
    @metrics = {
      # ì‹œê°„ ê´€ë ¨ ë©”íŠ¸ë¦­
      total_duration: duration,
      lines_per_second: @processed_lines / duration,
      average_line_time: duration / @processed_lines,
      
      # ë©”ëª¨ë¦¬ ê´€ë ¨ ë©”íŠ¸ë¦­
      start_memory_mb: bytes_to_mb(@start_memory),
      peak_memory_mb: bytes_to_mb(@peak_memory),
      memory_used_mb: bytes_to_mb(memory_used),
      memory_per_line_bytes: memory_used / @processed_lines,
      
      # ì²˜ë¦¬ ê´€ë ¨ ë©”íŠ¸ë¦­
      total_lines: @processed_lines,
      total_errors: @errors.size,
      error_rate: (@errors.size.to_f / @processed_lines * 100).round(4),
      success_rate: (100 - (@errors.size.to_f / @processed_lines * 100)).round(4),
      
      # ì²´í¬í¬ì¸íŠ¸ ì •ë³´
      checkpoints: @checkpoints,
      errors: @errors
    }
  end

  # ìƒì„¸ ë¦¬í¬íŠ¸ ìƒì„±
  def generate_report
    return "Benchmark not completed" unless @metrics

    report = []
    report << "=" * 60
    report << "REGULATION PARSER BENCHMARK REPORT"
    report << "=" * 60
    report << ""
    
    # ê¸°ë³¸ ì •ë³´
    report << "ğŸ“Š PROCESSING SUMMARY"
    report << "-" * 30
    report << "Total Lines Processed: #{@metrics[:total_lines].to_s.reverse.gsub(/(\d{3})(?=\d)/, '\\1,').reverse}"
    report << "Total Duration: #{format_duration(@metrics[:total_duration])}"
    report << "Processing Speed: #{@metrics[:lines_per_second].round(2)} lines/sec"
    report << "Average Time per Line: #{(@metrics[:average_line_time] * 1000).round(4)} ms"
    report << ""
    
    # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
    report << "ğŸ’¾ MEMORY USAGE"
    report << "-" * 30
    report << "Start Memory: #{@metrics[:start_memory_mb]} MB"
    report << "Peak Memory: #{@metrics[:peak_memory_mb]} MB"
    report << "Memory Used: #{@metrics[:memory_used_mb]} MB"
    report << "Memory per Line: #{@metrics[:memory_per_line_bytes]} bytes"
    report << ""
    
    # ì—ëŸ¬ í†µê³„
    report << "âŒ ERROR STATISTICS"
    report << "-" * 30
    report << "Total Errors: #{@metrics[:total_errors]}"
    report << "Error Rate: #{@metrics[:error_rate]}%"
    report << "Success Rate: #{@metrics[:success_rate]}%"
    report << ""
    
    # ì„±ëŠ¥ ë“±ê¸‰
    report << "ğŸ† PERFORMANCE GRADE"
    report << "-" * 30
    report << "Speed Grade: #{speed_grade}"
    report << "Memory Grade: #{memory_grade}"
    report << "Accuracy Grade: #{accuracy_grade}"
    report << "Overall Grade: #{overall_grade}"
    report << ""
    
    # ì²´í¬í¬ì¸íŠ¸ (ìµœê·¼ 5ê°œë§Œ)
    if @metrics[:checkpoints].any?
      report << "ğŸ“ RECENT CHECKPOINTS"
      report << "-" * 30
      @metrics[:checkpoints].last(5).each do |checkpoint|
        time_offset = (checkpoint[:timestamp] - @start_time).round(2)
        report << "[#{time_offset}s] #{checkpoint[:message]} (#{bytes_to_mb(checkpoint[:memory_usage])} MB)"
      end
      report << ""
    end
    
    # ì—ëŸ¬ ìƒì„¸ (ìµœê·¼ 5ê°œë§Œ)
    if @metrics[:errors].any?
      report << "ğŸš¨ RECENT ERRORS"
      report << "-" * 30
      @metrics[:errors].last(5).each do |error_info|
        time_offset = (error_info[:timestamp] - @start_time).round(2)
        report << "[#{time_offset}s] Line #{error_info[:line_number]}: #{error_info[:error]}"
      end
      report << ""
    end
    
    report << "=" * 60
    report.join("\n")
  end

  # JSON í˜•íƒœë¡œ ë©”íŠ¸ë¦­ ë°˜í™˜
  def to_json
    @metrics&.to_json
  end

  # CSV í˜•íƒœë¡œ ë©”íŠ¸ë¦­ ë°˜í™˜
  def to_csv
    return "" unless @metrics

    headers = %w[
      total_duration lines_per_second memory_used_mb
      total_lines total_errors error_rate success_rate
    ]
    
    values = headers.map { |key| @metrics[key.to_sym] }
    
    "#{headers.join(',')}\n#{values.join(',')}"
  end

  private

  # í˜„ì¬ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ (ë°”ì´íŠ¸)
  def current_memory_usage
    if RUBY_PLATFORM =~ /darwin/ # macOS
      `ps -o rss= -p #{Process.pid}`.to_i * 1024
    else # Linux
      `ps -o rss= -p #{Process.pid}`.to_i * 1024
    end
  rescue
    0 # ë©”ëª¨ë¦¬ ì¸¡ì • ì‹¤íŒ¨ ì‹œ 0 ë°˜í™˜
  end

  # ë°”ì´íŠ¸ë¥¼ MBë¡œ ë³€í™˜
  def bytes_to_mb(bytes)
    (bytes / 1024.0 / 1024.0).round(2)
  end

  # ì‹œê°„ í¬ë§·íŒ…
  def format_duration(seconds)
    if seconds < 60
      "#{seconds.round(2)}s"
    elsif seconds < 3600
      minutes = (seconds / 60).to_i
      remaining_seconds = (seconds % 60).round(2)
      "#{minutes}m #{remaining_seconds}s"
    else
      hours = (seconds / 3600).to_i
      remaining_minutes = ((seconds % 3600) / 60).to_i
      remaining_seconds = (seconds % 60).round(2)
      "#{hours}h #{remaining_minutes}m #{remaining_seconds}s"
    end
  end

  # ì†ë„ ë“±ê¸‰ ê³„ì‚°
  def speed_grade
    lines_per_sec = @metrics[:lines_per_second]
    case lines_per_sec
    when 0..100 then "D (Very Slow)"
    when 100..500 then "C (Slow)"
    when 500..1000 then "B (Good)"
    when 1000..2000 then "A (Fast)"
    else "A+ (Very Fast)"
    end
  end

  # ë©”ëª¨ë¦¬ ë“±ê¸‰ ê³„ì‚°
  def memory_grade
    memory_per_line = @metrics[:memory_per_line_bytes]
    case memory_per_line
    when 0..100 then "A+ (Excellent)"
    when 100..500 then "A (Good)"
    when 500..1000 then "B (Fair)"
    when 1000..2000 then "C (Poor)"
    else "D (Very Poor)"
    end
  end

  # ì •í™•ë„ ë“±ê¸‰ ê³„ì‚°
  def accuracy_grade
    success_rate = @metrics[:success_rate]
    case success_rate
    when 99..100 then "A+ (Excellent)"
    when 95..99 then "A (Good)"
    when 90..95 then "B (Fair)"
    when 80..90 then "C (Poor)"
    else "D (Very Poor)"
    end
  end

  # ì „ì²´ ë“±ê¸‰ ê³„ì‚°
  def overall_grade
    speed_score = case @metrics[:lines_per_second]
                  when 0..100 then 1
                  when 100..500 then 2
                  when 500..1000 then 3
                  when 1000..2000 then 4
                  else 5
                  end

    memory_score = case @metrics[:memory_per_line_bytes]
                   when 0..100 then 5
                   when 100..500 then 4
                   when 500..1000 then 3
                   when 1000..2000 then 2
                   else 1
                   end

    accuracy_score = case @metrics[:success_rate]
                     when 99..100 then 5
                     when 95..99 then 4
                     when 90..95 then 3
                     when 80..90 then 2
                     else 1
                     end

    average_score = (speed_score + memory_score + accuracy_score) / 3.0

    case average_score
    when 4.5..5.0 then "A+ (Outstanding)"
    when 3.5..4.5 then "A (Excellent)"
    when 2.5..3.5 then "B (Good)"
    when 1.5..2.5 then "C (Fair)"
    else "D (Needs Improvement)"
    end
  end
end